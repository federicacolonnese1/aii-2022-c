{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc67ea-2e14-46ed-b1b8-68b04c73c116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b576d28-aad1-46e9-b6d2-6566bbde4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a154f12-791b-4649-a30b-9d3e8bc01b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import of the dataset divided into two folders: x_aut, x_typical\n",
    "X_aut = []\n",
    "X_typical = []\n",
    "path = r\"C:\\Users\\\\feder\\\\Desktop\\\\X_aut\"\n",
    "files = os.listdir(path)\n",
    "files.sort()\n",
    "for f in files:\n",
    "    new_string = path+'\\\\'+str(f)\n",
    "    data = pd.read_excel(new_string, 'Sheet1')\n",
    "    df = pd.DataFrame(data)\n",
    "    df1 = df.iloc[:,1:76]\n",
    "    df2 = df1.set_axis(['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52','53','54','55','56','57','58','59','60','61','62','63','64','65','66','67','68','69','70','71','72','73','74','75'], axis=1, inplace=False)\n",
    "    X_aut.append(df2)\n",
    "    new_string = ''\n",
    "\n",
    "path2 = r\"C:\\Users\\\\feder\\\\Desktop\\\\X_typical\"\n",
    "files2 = os.listdir(path2)\n",
    "\n",
    "for f in files2:\n",
    "    new_string = path2+'\\\\'+str(f)\n",
    "    data = pd.read_excel(new_string, 'Sheet1')\n",
    "    df = pd.DataFrame(data)\n",
    "    df1 = df.iloc[:,1:76]\n",
    "    df2 = df1.set_axis(['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52','53','54','55','56','57','58','59','60','61','62','63','64','65','66','67','68','69','70','71','72','73','74','75'], axis=1, inplace=False)\n",
    "    X_typical.append(df2)\n",
    "    new_string = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd6b35a-2a81-4c89-964c-8fc407e1ae75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving the imported dataset\n",
    "import pickle\n",
    "with open('X_aut.pickle', 'wb') as output:\n",
    "    pickle.dump(X_aut, output)\n",
    "with open('X_typical.pickle', 'wb') as output:\n",
    "    pickle.dump(X_typical, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ee9e9f-2040-48c0-8580-adedf1de6d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('X_aut.pickle', 'rb') as data:\n",
    "    X_aut = pickle.load(data)\n",
    "with open('X_typical.pickle', 'rb') as data:\n",
    "    X_typical = pickle.load(data)\n",
    "    \n",
    "print(len(X_aut))\n",
    "print(len(X_typical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577607d5-8ee1-47a5-a3f5-e5aab5b2a881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(400,)\n",
      "[64, 66, 67, 68, 70, 71, 80, 82, 83, 84, 86, 87, 141, 176, 178, 179, 180, 181, 182, 183, 188, 205, 208, 276, 310, 326, 349] 27\n",
      "[25, 26, 27, 29, 30, 31, 32, 50, 51, 53, 54, 55, 56, 80, 81, 83, 84, 85, 86, 88, 89, 91, 92, 94, 95, 112, 113, 114, 115, 116, 118, 119, 130, 136, 137, 140, 142, 143, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 171, 172, 173, 174, 202, 234, 257, 279, 339] 63\n",
      "[] 0\n"
     ]
    }
   ],
   "source": [
    "#check if there are any duplicates in x_aut, x_typical and between x_aut x_typical\n",
    "#X_aut\n",
    "X_aut = np.asarray(X_aut,dtype=object)\n",
    "print(np.shape(X_aut))\n",
    "lista = []\n",
    "count = 0\n",
    "for i in range (len(X_aut)):\n",
    "    bambino1 = X_aut[i]\n",
    "    for j in range (len(X_aut)):\n",
    "        if i<j :\n",
    "            bambino2 = X_aut[j]\n",
    "            flag = np.array_equal(bambino1, bambino2)\n",
    "            if (flag == True) and (i not in lista):\n",
    "                count+=1\n",
    "                lista.append(i)\n",
    "\n",
    "#check X_typical\n",
    "X_typical = np.asarray(X_typical,dtype=object)\n",
    "print(np.shape(X_typical))\n",
    "lista2 = []\n",
    "count2 = 0\n",
    "for i in range (len(X_typical)):\n",
    "    bambino3 = X_typical[i]\n",
    "    for j in range (len(X_typical)):\n",
    "        if i<j :\n",
    "            bambino4 = X_typical[j]\n",
    "            flag = np.array_equal(bambino3, bambino4)\n",
    "            if (flag == True) and (i not in lista2):\n",
    "                count2+=1\n",
    "                lista2.append(i)\n",
    "\n",
    "#X_aut, X_typical\n",
    "lista3 = []\n",
    "count3 = 0\n",
    "for i in range (len(X_typical)):\n",
    "    bambino5 = X_typical[i]\n",
    "    for j in range (len(X_aut)):\n",
    "        if i<j :\n",
    "            bambino6 = X_aut[j]\n",
    "            flag = np.array_equal(bambino5, bambino6)\n",
    "            if (flag == True) and (i not in lista3):\n",
    "                count3+=1\n",
    "                lista3.append(i)\n",
    "                \n",
    "print(lista, count)\n",
    "print(lista2, count2)\n",
    "print(lista3, count3)\n",
    "\n",
    "\n",
    "X_aut = X_aut.tolist()\n",
    "X_aut2 = []\n",
    "for i in range (1, len(X_aut)):\n",
    "    if i not in lista:\n",
    "        X_aut2.append(X_aut[i])\n",
    "        \n",
    "X_typical = X_typical.tolist()\n",
    "X_typical2 = []\n",
    "for i in range (1, len(X_typical)):\n",
    "    if i not in lista2:\n",
    "        X_typical2.append(X_typical[i])\n",
    "        \n",
    "print(np.shape(X_aut2))\n",
    "print(np.shape(X_typical2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998e69fd-b85c-4c33-b9c7-6069bc840c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n",
      "336\n"
     ]
    }
   ],
   "source": [
    "#final dataset \n",
    "\n",
    "#y\n",
    "path_y_aut = r\"C:\\Users\\\\feder\\\\Desktop\\\\y_aut.xlsx\"\n",
    "df = pd.read_excel(path_y_aut)\n",
    "Y_aut= np.asarray(df['AUT'],dtype=object)\n",
    "path_y_typical = r\"C:\\Users\\\\feder\\\\Desktop\\\\y_typical.xlsx\"\n",
    "df2 = pd.read_excel(path_y_typical)\n",
    "Y_typical= np.asarray(df2['TYPICAL'],dtype=object)\n",
    "Y= np.append(Y_aut, Y_typical)\n",
    "#X_aut2 = np.asarray(X_aut2,dtype=object)\n",
    "#X_typical2 = np.asarray(X_typical2,dtype=object)\n",
    "print(len(Y_aut))\n",
    "print(len(Y_typical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c758004b-b6f2-4f8b-84f9-db89435da496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372,)\n",
      "(336,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#shuffle of x_aut and x_typical \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_aut2 = shuffle(X_aut2)\n",
    "X_typical2 = shuffle(X_typical2)\n",
    "print(np.shape(X_aut2))\n",
    "print(np.shape(X_typical2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54e6b1f-6a6d-44b5-8207-a5d2d6581ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297,)\n",
      "(75,)\n",
      "(268,)\n",
      "(68,)\n"
     ]
    }
   ],
   "source": [
    "#creation of training and test sets (80% training and 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_aut, test_aut = train_test_split(X_aut2, test_size=0.20, random_state=25)\n",
    "train_typical, test_typical = train_test_split(X_typical2, test_size=0.20, random_state=25)\n",
    "\n",
    "print(np.shape(train_aut))\n",
    "print(np.shape(test_aut))\n",
    "print(np.shape(train_typical))\n",
    "print(np.shape(test_typical))\n",
    "\n",
    "#X_train = np.asarray(train_aut + train_typical, dtype=object)\n",
    "#X_test = np.asarray(test_aut + test_typical, dtype=object)\n",
    "\n",
    "X_train = np.append(train_aut, train_typical)\n",
    "X_train = np.asarray(X_train, dtype=object)\n",
    "\n",
    "X_test = np.append(test_aut, test_typical)\n",
    "X_test = np.asarray(X_test, dtype=object)\n",
    "\n",
    "Y_train = np.append(Y_aut[0:297],Y_typical[0:268])\n",
    "Y_train = np.asarray(Y_train, dtype=object)\n",
    "\n",
    "Y_test = np.append(Y_aut[297:372],Y_typical[268:336])\n",
    "Y_test = np.asarray(Y_test, dtype=object)\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(Y_train))\n",
    "print(np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f83db1-e77a-498e-be30-ff6c5cc388eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function for evaluating the average lenght of frames in X_train\n",
    "lunghezza = []\n",
    "for i in range(len(X_train)):\n",
    "    lunghezza.append(len(X_train[i]))\n",
    "avg_len = round(np.average(lunghezza))\n",
    "print(avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688eb1d-60d4-489e-84c1-4db44a4f3737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fuction for padding on the average lenght\n",
    "def padding(val, avglen):\n",
    "    for i in range (len(val)):\n",
    "        righe = 0\n",
    "        if len(val[i]) <= avglen:\n",
    "            x2 = []\n",
    "            righe = avglen - len(val[i])\n",
    "            val[i] = val[i].reindex(range(avg_len)).fillna(0, downcast='infer')\n",
    "            val[i] = val[i]\n",
    "        else: \n",
    "            righe = len(val[i]) - avglen\n",
    "            val[i] = val[i][:-righe]\n",
    "                        \n",
    "    return val\n",
    "\n",
    "X_test_p= padding(X_test, avg_len)\n",
    "X_train_p = padding(X_train, avg_len)\n",
    "X_aut_p = padding(X_aut2, avg_len)\n",
    "X_typical_p = padding(X_typical2, avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3887846-b77e-4fae-a246-94b8d67d3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train_p))\n",
    "print(len(X_test_p))\n",
    "print(len(X_aut2))\n",
    "print(len(X_typical2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91810f-30f0-4c0c-a73c-9f7bce1400bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fuction for correctly reshaping the dataset\n",
    "def input_shape(val, avglen, n):\n",
    "    for i in range(n):\n",
    "        sample = val[i]\n",
    "        sample = np.asarray(sample)\n",
    "        sample = np.reshape(sample, (1,avglen,75))\n",
    "        if i == 0:\n",
    "            new_val =sample\n",
    "            \n",
    "        else:\n",
    "            new_val = np.concatenate((new_val,sample),axis = 0)\n",
    "    return new_val \n",
    "\n",
    "X_train_padded = input_shape(X_train_p, avg_len, 565)\n",
    "X_test_padded = input_shape(X_test_p, avg_len, 143)\n",
    "X_train_shape = np.shape(X_train_padded)\n",
    "X_shape_sample = np.shape(X_train_padded[0])\n",
    "\n",
    "#X_aut_padded = input_shape(X_aut_p, avg_len, 50)\n",
    "#X_typical_padded = input_shape(X_typical_p, avg_len, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d24600-fb87-4c8c-a46f-3da3f2664768",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)\n",
    "\n",
    "#dataset normalization \n",
    "mean = np.mean(X_train_padded)\n",
    "std = np.std(X_train_padded)\n",
    "X_train_padded = (X_train_padded - mean)/std\n",
    "X_test_padded = (X_test_padded - mean)/std\n",
    "\n",
    "print(np.shape(X_train_padded))\n",
    "print(X_shape_sample)\n",
    "print(np.shape(Y_train))\n",
    "print(np.shape(Y_test))\n",
    "print(np.shape(X_test_padded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4eba94-21f4-41ab-b838-0c151e1e8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataset\n",
    "import pickle\n",
    "with open('X_train2.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train_padded, output)\n",
    "with open('X_test2.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test_padded, output)\n",
    "with open('Y_test2.pickle', 'wb') as output:\n",
    "    pickle.dump(Y_test, output)\n",
    "with open('Y_train2.pickle', 'wb') as output:\n",
    "    pickle.dump(Y_train, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a98e92-49de-431e-85fe-9a699ed0e13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
